{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EZ6Tww_qB3ck2wM1MMirwhRUZ74j3mBS",
      "authorship_tag": "ABX9TyPfNbOLf5QZen9AUjyw6pAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshgupta01/BCancerGogo/blob/main/GOGOvgg19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knQYrf5VM7fv",
        "outputId": "80c9a25e-fe50-4083-e707-f385a77d729f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Images: 321\n",
            "Shape of an Image: (224, 224, 3)\n",
            "Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 16\n",
        "\n",
        "def label_images(directory, target_size=(img_width, img_height)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_labels = {'malignant': 0, 'benign': 1, 'normal': 2}\n",
        "\n",
        "    for class_label, class_index in class_labels.items():\n",
        "        class_path = os.path.join(directory, class_label)\n",
        "        for filename in os.listdir(class_path):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                file_path = os.path.join(class_path, filename)\n",
        "                image = cv2.imread(file_path)  # You can use PIL.Image.open() as well\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "                image = cv2.resize(image, target_size)  # Resize the image to target size\n",
        "                image = preprocess_input(image)  # Preprocess the image for VGG16\n",
        "                images.append(image)\n",
        "                labels.append(class_index)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "directory_path = '/content/drive/MyDrive/MIASdata'\n",
        "X, y = label_images(directory_path, target_size=(img_width, img_height))\n",
        "\n",
        "# X contains the resized images, and y contains the corresponding labels\n",
        "print(f\"Total Images: {len(X)}\")\n",
        "print(f\"Shape of an Image: {X[0].shape}\")\n",
        "print(f\"Labels: {y}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bOfurEINY9B",
        "outputId": "45190b9d-c541-46ad-9b8d-a29170297f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 288 samples\n",
            "Testing Set: 33 samples\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are the images and labels obtained from the previous code\n",
        "# X, y = label_images(directory_path)\n",
        "\n",
        "# Split the data into 90% training and 10% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Print the sizes of the training and testing sets\n",
        "print(f\"Training Set: {len(X_train)} samples\")\n",
        "print(f\"Testing Set: {len(X_test)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have three classes (malignant, benign, normal)\n",
        "num_classes = 3\n",
        "img_width, img_height = 224, 224  # Adjust these dimensions based on your data\n",
        "\n",
        "def build_vgg19_model(learn_rate=1e-4, momentum=0.9):\n",
        "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "    # Freeze all layers except the last three\n",
        "    for layer in base_model.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    optimizer = SGD(learning_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build a new VGG19 model\n",
        "vgg19_model = build_vgg19_model()\n",
        "\n",
        "# Number of folds for k-fold cross-validation\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(X, y), 1):\n",
        "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train_fold_one_hot = to_categorical(y_train_fold, num_classes=num_classes)\n",
        "    y_val_fold_one_hot = to_categorical(y_val_fold, num_classes=num_classes)\n",
        "\n",
        "    # Train the VGG19 model\n",
        "    class_weights = {0: 4.0, 1: 4.0, 2: 1.0}  # Adjust the weights based on class imbalance\n",
        "\n",
        "    history = vgg19_model.fit(\n",
        "        X_train_fold,\n",
        "        y_train_fold_one_hot,\n",
        "        epochs=10,\n",
        "        validation_data=(X_val_fold, y_val_fold_one_hot),\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        class_weight=class_weights\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_acc = vgg19_model.evaluate(X_val_fold, y_val_fold_one_hot, verbose=0)\n",
        "    print(f\"Validation Accuracy for Fold {fold}: {val_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe7BMqGCCVOm",
        "outputId": "b505dac1-b856-4f70-8d45-b4920e91eaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 313s 40s/step - loss: 3.1583 - accuracy: 0.3242 - val_loss: 3.5590 - val_accuracy: 0.2769\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 282s 37s/step - loss: 1.1666 - accuracy: 0.6172 - val_loss: 2.4153 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 306s 40s/step - loss: 0.6107 - accuracy: 0.7969 - val_loss: 2.5222 - val_accuracy: 0.4308\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 315s 41s/step - loss: 0.4389 - accuracy: 0.8750 - val_loss: 2.0625 - val_accuracy: 0.4308\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 306s 39s/step - loss: 0.3174 - accuracy: 0.9414 - val_loss: 1.7532 - val_accuracy: 0.4462\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 307s 40s/step - loss: 0.2297 - accuracy: 0.9805 - val_loss: 1.5886 - val_accuracy: 0.4615\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 306s 40s/step - loss: 0.2108 - accuracy: 0.9844 - val_loss: 1.5325 - val_accuracy: 0.4615\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 308s 40s/step - loss: 0.1653 - accuracy: 0.9883 - val_loss: 1.5678 - val_accuracy: 0.4615\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 306s 40s/step - loss: 0.1466 - accuracy: 0.9922 - val_loss: 1.5682 - val_accuracy: 0.4615\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 309s 40s/step - loss: 0.1220 - accuracy: 0.9961 - val_loss: 1.5334 - val_accuracy: 0.4462\n",
            "Validation Accuracy for Fold 1: 44.62%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.9160 - accuracy: 0.8560 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 278s 31s/step - loss: 0.5175 - accuracy: 0.9066 - val_loss: 0.2779 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.3172 - accuracy: 0.9533 - val_loss: 0.1213 - val_accuracy: 0.9844\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 276s 31s/step - loss: 0.2280 - accuracy: 0.9844 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 275s 31s/step - loss: 0.1585 - accuracy: 0.9883 - val_loss: 0.1018 - val_accuracy: 0.9688\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 309s 35s/step - loss: 0.2162 - accuracy: 0.9844 - val_loss: 0.1204 - val_accuracy: 0.9688\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.1925 - accuracy: 0.9805 - val_loss: 0.1359 - val_accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 309s 35s/step - loss: 0.1601 - accuracy: 0.9883 - val_loss: 0.1354 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 275s 31s/step - loss: 0.1657 - accuracy: 0.9883 - val_loss: 0.1338 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.1284 - accuracy: 0.9883 - val_loss: 0.1282 - val_accuracy: 0.9844\n",
            "Validation Accuracy for Fold 2: 98.44%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 279s 31s/step - loss: 0.2076 - accuracy: 0.9572 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.2017 - accuracy: 0.9883 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.1754 - accuracy: 0.9844 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.1548 - accuracy: 0.9922 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.1078 - accuracy: 0.9922 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 313s 35s/step - loss: 0.1942 - accuracy: 0.9961 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 313s 35s/step - loss: 0.1167 - accuracy: 0.9883 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.0942 - accuracy: 0.9961 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 312s 36s/step - loss: 0.1259 - accuracy: 0.9922 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 276s 31s/step - loss: 0.1021 - accuracy: 0.9883 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Validation Accuracy for Fold 3: 100.00%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 310s 35s/step - loss: 0.1191 - accuracy: 0.9922 - val_loss: 0.0519 - val_accuracy: 0.9688\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 309s 35s/step - loss: 0.0876 - accuracy: 0.9961 - val_loss: 0.0943 - val_accuracy: 0.9688\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 311s 35s/step - loss: 0.1092 - accuracy: 0.9922 - val_loss: 0.1522 - val_accuracy: 0.9688\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 308s 35s/step - loss: 0.0816 - accuracy: 0.9961 - val_loss: 0.1800 - val_accuracy: 0.9688\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 312s 35s/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9688\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9688\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9688\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 276s 31s/step - loss: 0.0668 - accuracy: 0.9961 - val_loss: 0.1857 - val_accuracy: 0.9688\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.0734 - accuracy: 0.9961 - val_loss: 0.1939 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 311s 36s/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9688\n",
            "Validation Accuracy for Fold 4: 96.88%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 322s 36s/step - loss: 0.1740 - accuracy: 0.9883 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 313s 35s/step - loss: 0.0733 - accuracy: 0.9961 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 277s 31s/step - loss: 0.0699 - accuracy: 0.9922 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 309s 35s/step - loss: 0.0932 - accuracy: 0.9961 - val_loss: 0.0425 - val_accuracy: 0.9844\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.1060 - accuracy: 0.9922 - val_loss: 0.0447 - val_accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 311s 35s/step - loss: 0.0784 - accuracy: 0.9961 - val_loss: 0.0503 - val_accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 307s 35s/step - loss: 0.0781 - accuracy: 0.9961 - val_loss: 0.0555 - val_accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 311s 35s/step - loss: 0.0929 - accuracy: 0.9922 - val_loss: 0.0521 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 306s 35s/step - loss: 0.0737 - accuracy: 0.9922 - val_loss: 0.0531 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 310s 35s/step - loss: 0.0804 - accuracy: 0.9922 - val_loss: 0.0539 - val_accuracy: 0.9844\n",
            "Validation Accuracy for Fold 5: 98.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y_test_one_hot=to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Function to calculate and print evaluation metrics\n",
        "def evaluate_model_multi_class(model, X, y_true):\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # Convert one-hot encoding to class labels\n",
        "    y_true_labels = np.argmax(y_true, axis=1)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true_labels, y_pred_labels))\n",
        "\n",
        "# Assuming you have trained the model 'inception_model' and loaded the test set 'X_val_fold', 'y_val_fold_one_hot'\n",
        "evaluate_model_multi_class(vgg19_model, X_test, y_test_one_hot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKrMOYgwCvA7",
        "outputId": "e9d7ba54-5358-45bd-8ffc-e1ed2384126c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 27s 741ms/step\n",
            "Accuracy: 100.00%\n",
            "Confusion Matrix:\n",
            "[[ 4  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 20]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        33\n",
            "   macro avg       1.00      1.00      1.00        33\n",
            "weighted avg       1.00      1.00      1.00        33\n",
            "\n"
          ]
        }
      ]
    }
  ]
}