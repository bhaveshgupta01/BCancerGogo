{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe3f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 2000\n",
      "Shape of an Image: (224, 224, 3)\n",
      "Labels: [0 0 0 ... 1 1 1]\n",
      "Training Set: 1800 samples\n",
      "Testing Set: 200 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 8\n",
    "\n",
    "# ... (GPU availability and memory growth code from previous response)\n",
    "def label_images(directory, target_size=(img_width, img_height), max_images_per_class=1000):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = {'Malignant': 0, 'Benign': 1}\n",
    "\n",
    "    for class_label, class_index in class_labels.items():\n",
    "        class_path = os.path.join(directory, class_label)\n",
    "        image_count = 0\n",
    "        for root, _, files in os.walk(class_path):\n",
    "            for filename in files:\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    if image_count < max_images_per_class:\n",
    "                        file_path = os.path.join(root, filename)\n",
    "                        image = load_img(file_path, target_size=target_size)  # Load with GPU\n",
    "                        image = img_to_array(image)\n",
    "                        image = preprocess_input(image)  # Process the image after loading\n",
    "                        images.append(image)\n",
    "                        labels.append(class_index)\n",
    "                        image_count += 1\n",
    "                    else:\n",
    "                        break  # Stop processing this class if max images reached\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Example usage:\n",
    "directory_path = 'G:/ChineseCheck/'\n",
    "X, y = label_images(directory_path, target_size=(img_width, img_height))\n",
    "\n",
    "# X contains the resized images, and y contains the corresponding labels\n",
    "print(f\"Total Images: {len(X)}\")\n",
    "print(f\"Shape of an Image: {X[0].shape}\")\n",
    "print(f\"Labels: {y}\")\n",
    "\n",
    "# Assuming X and y are the images and labels obtained from the previous code\n",
    "# X, y = label_images(directory_path)\n",
    "\n",
    "# Split the data into 90% training and 10% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print the sizes of the training and testing sets\n",
    "print(f\"Training Set: {len(X_train)} samples\")\n",
    "print(f\"Testing Set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c599812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 822ms/step - accuracy: 0.5425 - loss: 0.8938 - val_accuracy: 0.5900 - val_loss: 0.7398\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 816ms/step - accuracy: 0.6828 - loss: 0.5959 - val_accuracy: 0.5950 - val_loss: 0.7578\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 808ms/step - accuracy: 0.7620 - loss: 0.5003 - val_accuracy: 0.5400 - val_loss: 0.7777\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 722ms/step - accuracy: 0.7778 - loss: 0.4859 - val_accuracy: 0.5475 - val_loss: 0.8283\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 597ms/step - accuracy: 0.8067 - loss: 0.4367 - val_accuracy: 0.5700 - val_loss: 0.7925\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 805ms/step - accuracy: 0.8329 - loss: 0.3893 - val_accuracy: 0.5400 - val_loss: 0.9145\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 797ms/step - accuracy: 0.8544 - loss: 0.3695 - val_accuracy: 0.5575 - val_loss: 0.8356\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 562ms/step - accuracy: 0.8798 - loss: 0.3207 - val_accuracy: 0.5525 - val_loss: 1.0749\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 578ms/step - accuracy: 0.9028 - loss: 0.2805 - val_accuracy: 0.5575 - val_loss: 0.8812\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 605ms/step - accuracy: 0.9154 - loss: 0.2636 - val_accuracy: 0.5775 - val_loss: 0.9797\n",
      "Validation Accuracy for Fold 1: 57.75%\n",
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 577ms/step - accuracy: 0.8097 - loss: 0.4310 - val_accuracy: 0.9050 - val_loss: 0.2794\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 578ms/step - accuracy: 0.8477 - loss: 0.3676 - val_accuracy: 0.8725 - val_loss: 0.3396\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 578ms/step - accuracy: 0.8596 - loss: 0.3395 - val_accuracy: 0.8650 - val_loss: 0.3489\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 573ms/step - accuracy: 0.8641 - loss: 0.3263 - val_accuracy: 0.7575 - val_loss: 0.5405\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 560ms/step - accuracy: 0.8954 - loss: 0.2893 - val_accuracy: 0.7700 - val_loss: 0.4609\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 565ms/step - accuracy: 0.8959 - loss: 0.2704 - val_accuracy: 0.8125 - val_loss: 0.4104\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 550ms/step - accuracy: 0.9077 - loss: 0.2572 - val_accuracy: 0.8150 - val_loss: 0.4143\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 570ms/step - accuracy: 0.9236 - loss: 0.2494 - val_accuracy: 0.8150 - val_loss: 0.4066\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 573ms/step - accuracy: 0.9237 - loss: 0.2230 - val_accuracy: 0.7750 - val_loss: 0.4398\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 566ms/step - accuracy: 0.9516 - loss: 0.1905 - val_accuracy: 0.7600 - val_loss: 0.4770\n",
      "Validation Accuracy for Fold 2: 76.00%\n",
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 562ms/step - accuracy: 0.8615 - loss: 0.3442 - val_accuracy: 0.9450 - val_loss: 0.2086\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 569ms/step - accuracy: 0.8780 - loss: 0.3126 - val_accuracy: 0.9225 - val_loss: 0.2285\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 571ms/step - accuracy: 0.8850 - loss: 0.2866 - val_accuracy: 0.9025 - val_loss: 0.2515\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 566ms/step - accuracy: 0.9015 - loss: 0.2649 - val_accuracy: 0.9125 - val_loss: 0.2374\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 563ms/step - accuracy: 0.9181 - loss: 0.2406 - val_accuracy: 0.8625 - val_loss: 0.3216\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 576ms/step - accuracy: 0.9431 - loss: 0.2051 - val_accuracy: 0.8600 - val_loss: 0.3050\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 589ms/step - accuracy: 0.9320 - loss: 0.2145 - val_accuracy: 0.8125 - val_loss: 0.3628\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - accuracy: 0.9195 - loss: 0.2266 - val_accuracy: 0.8850 - val_loss: 0.2770\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 592ms/step - accuracy: 0.9332 - loss: 0.2073 - val_accuracy: 0.8350 - val_loss: 0.3699\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 582ms/step - accuracy: 0.9509 - loss: 0.1791 - val_accuracy: 0.8875 - val_loss: 0.3079\n",
      "Validation Accuracy for Fold 3: 88.75%\n",
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - accuracy: 0.8934 - loss: 0.2580 - val_accuracy: 0.9625 - val_loss: 0.1608\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 587ms/step - accuracy: 0.9120 - loss: 0.2443 - val_accuracy: 0.9050 - val_loss: 0.2363\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 641ms/step - accuracy: 0.9235 - loss: 0.2380 - val_accuracy: 0.8675 - val_loss: 0.3133\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 597ms/step - accuracy: 0.9137 - loss: 0.2462 - val_accuracy: 0.8425 - val_loss: 0.3712\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 587ms/step - accuracy: 0.9382 - loss: 0.2284 - val_accuracy: 0.8700 - val_loss: 0.2807\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 598ms/step - accuracy: 0.9375 - loss: 0.2138 - val_accuracy: 0.8900 - val_loss: 0.2996\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 576ms/step - accuracy: 0.9438 - loss: 0.2033 - val_accuracy: 0.7925 - val_loss: 0.3864\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 595ms/step - accuracy: 0.9381 - loss: 0.2001 - val_accuracy: 0.9000 - val_loss: 0.2709\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 587ms/step - accuracy: 0.9214 - loss: 0.2101 - val_accuracy: 0.8650 - val_loss: 0.3342\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 586ms/step - accuracy: 0.9435 - loss: 0.1934 - val_accuracy: 0.8675 - val_loss: 0.3246\n",
      "Validation Accuracy for Fold 4: 86.75%\n",
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 586ms/step - accuracy: 0.9160 - loss: 0.2352 - val_accuracy: 0.8925 - val_loss: 0.2525\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 832ms/step - accuracy: 0.9044 - loss: 0.2527 - val_accuracy: 0.9375 - val_loss: 0.1946\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 745ms/step - accuracy: 0.9100 - loss: 0.2467 - val_accuracy: 0.9400 - val_loss: 0.2194\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 583ms/step - accuracy: 0.9265 - loss: 0.2301 - val_accuracy: 0.9425 - val_loss: 0.1864\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 590ms/step - accuracy: 0.9398 - loss: 0.1969 - val_accuracy: 0.8725 - val_loss: 0.3054\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 605ms/step - accuracy: 0.9337 - loss: 0.2166 - val_accuracy: 0.9000 - val_loss: 0.2824\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 578ms/step - accuracy: 0.9440 - loss: 0.1888 - val_accuracy: 0.7375 - val_loss: 0.4941\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 594ms/step - accuracy: 0.9396 - loss: 0.1952 - val_accuracy: 0.8150 - val_loss: 0.3787\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 577ms/step - accuracy: 0.9543 - loss: 0.1678 - val_accuracy: 0.7850 - val_loss: 0.4300\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 582ms/step - accuracy: 0.9552 - loss: 0.1583 - val_accuracy: 0.9050 - val_loss: 0.2537\n",
      "Validation Accuracy for Fold 5: 90.50%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming you have three classes (malignant, benign, normal)\n",
    "num_classes = 2\n",
    "img_width, img_height = 224, 224  # Adjust these dimensions based on your data\n",
    "\n",
    "def build_inception_model(learn_rate=0.0001, momentum=0.9):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "    # Freeze all layers except the last three\n",
    "    for layer in base_model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=learn_rate, momentum=momentum)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build a new VGG19 model\n",
    "inception_model = build_inception_model()\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "num_folds = 5\n",
    "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=110)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(X, y), 1):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold_one_hot = to_categorical(y_train_fold, num_classes=num_classes)\n",
    "    y_val_fold_one_hot = to_categorical(y_val_fold, num_classes=num_classes)\n",
    "\n",
    "    # Train the VGG19 model\n",
    "    class_weights = {0: 1.0, 1: 3.0}  # Adjust the weights based on class imbalance\n",
    "\n",
    "    history = inception_model.fit(\n",
    "        X_train_fold,\n",
    "        y_train_fold_one_hot,\n",
    "        epochs=10,\n",
    "        validation_data=(X_val_fold, y_val_fold_one_hot),\n",
    "        batch_size=8,\n",
    "        verbose=1,\n",
    "#         class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = inception_model.evaluate(X_val_fold, y_val_fold_one_hot, verbose=0)\n",
    "    print(f\"Validation Accuracy for Fold {fold}: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bee0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step\n",
      "Accuracy: 90.50%\n",
      "Confusion Matrix:\n",
      "[[181  19]\n",
      " [ 19 181]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       200\n",
      "           1       0.91      0.91      0.91       200\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Function to calculate and print evaluation metrics\n",
    "def evaluate_model_multi_class(model, X, y_true):\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Convert one-hot encoding to class labels\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "# Assuming you have trained the model 'inception_model' and loaded the test set 'X_val_fold', 'y_val_fold_one_hot'\n",
    "evaluate_model_multi_class(inception_model, X_val_fold, y_val_fold_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713455d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
