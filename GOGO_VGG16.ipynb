{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshgupta01/BCancerGogo/blob/main/GOGO_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knQYrf5VM7fv",
        "outputId": "0799f3d2-2703-4fe3-927e-e7e000e01dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Images: 321\n",
            "Shape of an Image: (224, 224, 3)\n",
            "Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "# Image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 16\n",
        "\n",
        "def label_images(directory, target_size=(img_width, img_height)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_labels = {'malignant': 0, 'benign': 1, 'normal': 2}\n",
        "\n",
        "    for class_label, class_index in class_labels.items():\n",
        "        class_path = os.path.join(directory, class_label)\n",
        "        for filename in os.listdir(class_path):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                file_path = os.path.join(class_path, filename)\n",
        "                image = cv2.imread(file_path)  # You can use PIL.Image.open() as well\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "                image = cv2.resize(image, target_size)  # Resize the image to target size\n",
        "                image = preprocess_input(image)  # Preprocess the image for VGG16\n",
        "                images.append(image)\n",
        "                labels.append(class_index)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "directory_path = '/content/drive/MyDrive/MIASdata'\n",
        "X, y = label_images(directory_path, target_size=(img_width, img_height))\n",
        "\n",
        "# X contains the resized images, and y contains the corresponding labels\n",
        "print(f\"Total Images: {len(X)}\")\n",
        "print(f\"Shape of an Image: {X[0].shape}\")\n",
        "print(f\"Labels: {y}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bOfurEINY9B",
        "outputId": "ac0e0a66-63d1-42f1-bc74-3fa7a402eca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 288 samples\n",
            "Testing Set: 33 samples\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are the images and labels obtained from the previous code\n",
        "# X, y = label_images(directory_path)\n",
        "\n",
        "# Split the data into 90% training and 10% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Print the sizes of the training and testing sets\n",
        "print(f\"Training Set: {len(X_train)} samples\")\n",
        "print(f\"Testing Set: {len(X_test)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp2gJJgip1Wu",
        "outputId": "665f9b5c-50a4-4d1f-aeb9-ec58b0a6a75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 226s 29s/step - loss: 3.4791 - accuracy: 0.3320 - val_loss: 3.3280 - val_accuracy: 0.3385\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 231s 30s/step - loss: 1.3040 - accuracy: 0.5938 - val_loss: 3.9009 - val_accuracy: 0.2769\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 225s 29s/step - loss: 0.7227 - accuracy: 0.7188 - val_loss: 3.4145 - val_accuracy: 0.2769\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 268s 35s/step - loss: 0.5372 - accuracy: 0.8242 - val_loss: 2.4340 - val_accuracy: 0.2923\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 225s 29s/step - loss: 0.3780 - accuracy: 0.9219 - val_loss: 1.9179 - val_accuracy: 0.3846\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 269s 35s/step - loss: 0.3158 - accuracy: 0.9258 - val_loss: 1.7065 - val_accuracy: 0.4308\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 242s 31s/step - loss: 0.2640 - accuracy: 0.9688 - val_loss: 1.5348 - val_accuracy: 0.4462\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 236s 30s/step - loss: 0.2325 - accuracy: 0.9805 - val_loss: 1.5381 - val_accuracy: 0.4154\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 276s 36s/step - loss: 0.1955 - accuracy: 0.9883 - val_loss: 1.5318 - val_accuracy: 0.4769\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 226s 29s/step - loss: 0.1541 - accuracy: 0.9961 - val_loss: 1.4574 - val_accuracy: 0.4615\n",
            "Validation Accuracy for Fold 1: 46.15%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 270s 31s/step - loss: 0.8816 - accuracy: 0.8405 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 264s 30s/step - loss: 0.4826 - accuracy: 0.9222 - val_loss: 0.1056 - val_accuracy: 0.9688\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 267s 31s/step - loss: 0.4326 - accuracy: 0.9261 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 268s 30s/step - loss: 0.3555 - accuracy: 0.9494 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 226s 26s/step - loss: 0.2223 - accuracy: 0.9689 - val_loss: 0.0910 - val_accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 230s 26s/step - loss: 0.2572 - accuracy: 0.9650 - val_loss: 0.0936 - val_accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 264s 30s/step - loss: 0.1908 - accuracy: 0.9922 - val_loss: 0.0979 - val_accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 222s 25s/step - loss: 0.1485 - accuracy: 0.9883 - val_loss: 0.1135 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 224s 25s/step - loss: 0.1586 - accuracy: 0.9922 - val_loss: 0.1372 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 267s 30s/step - loss: 0.1250 - accuracy: 0.9922 - val_loss: 0.1525 - val_accuracy: 0.9688\n",
            "Validation Accuracy for Fold 2: 96.88%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 266s 30s/step - loss: 0.2088 - accuracy: 0.9728 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 223s 25s/step - loss: 0.1726 - accuracy: 0.9883 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 266s 30s/step - loss: 0.1403 - accuracy: 0.9922 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 266s 30s/step - loss: 0.1727 - accuracy: 0.9844 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 264s 30s/step - loss: 0.1800 - accuracy: 0.9844 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 230s 26s/step - loss: 0.1966 - accuracy: 0.9844 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 223s 25s/step - loss: 0.1661 - accuracy: 0.9883 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 266s 31s/step - loss: 0.1246 - accuracy: 0.9883 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 262s 30s/step - loss: 0.1417 - accuracy: 0.9922 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 266s 30s/step - loss: 0.1249 - accuracy: 0.9961 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
            "Validation Accuracy for Fold 3: 100.00%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 227s 25s/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9688\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 223s 25s/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9688\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 225s 25s/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9688\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 232s 26s/step - loss: 0.0766 - accuracy: 0.9961 - val_loss: 0.1491 - val_accuracy: 0.9688\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 275s 31s/step - loss: 0.0697 - accuracy: 0.9961 - val_loss: 0.1552 - val_accuracy: 0.9688\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 270s 31s/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9688\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 262s 30s/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9688\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 220s 25s/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9688\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 265s 30s/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 222s 25s/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9688\n",
            "Validation Accuracy for Fold 4: 96.88%\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 268s 31s/step - loss: 0.1199 - accuracy: 0.9922 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 225s 25s/step - loss: 0.0860 - accuracy: 0.9922 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 234s 26s/step - loss: 0.1064 - accuracy: 0.9883 - val_loss: 0.0362 - val_accuracy: 0.9844\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 222s 25s/step - loss: 0.0796 - accuracy: 0.9961 - val_loss: 0.0576 - val_accuracy: 0.9844\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 229s 26s/step - loss: 0.1437 - accuracy: 0.9844 - val_loss: 0.0643 - val_accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 227s 25s/step - loss: 0.0992 - accuracy: 0.9922 - val_loss: 0.0590 - val_accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 267s 31s/step - loss: 0.0726 - accuracy: 0.9961 - val_loss: 0.0549 - val_accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 264s 30s/step - loss: 0.0783 - accuracy: 0.9961 - val_loss: 0.0573 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 227s 25s/step - loss: 0.0958 - accuracy: 0.9961 - val_loss: 0.0572 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 227s 25s/step - loss: 0.1068 - accuracy: 0.9883 - val_loss: 0.0539 - val_accuracy: 0.9844\n",
            "Validation Accuracy for Fold 5: 98.44%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Assuming you have three classes (malignant, benign, normal)\n",
        "num_classes = 3\n",
        "\n",
        "def build_vgg_model(learn_rate=1e-4, momentum=0.9):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "    # Freeze all layers except the last three\n",
        "    for layer in base_model.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))  # Change activation to 'softmax'\n",
        "\n",
        "    optimizer = SGD(learning_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ... (your data loading and preprocessing code)\n",
        "vgg_model = build_vgg_model()\n",
        "\n",
        "# Number of folds for k-fold cross-validation\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(X, y), 1):\n",
        "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train_fold_one_hot = to_categorical(y_train_fold, num_classes=num_classes)\n",
        "    y_val_fold_one_hot = to_categorical(y_val_fold, num_classes=num_classes)\n",
        "\n",
        "    # Build a new VGG16 model for each fold\n",
        "\n",
        "    # Train the VGG16 model\n",
        "    class_weights = {0: 4.0, 1: 4.0, 2: 1.0}  # Adjust the weights based on class imbalance\n",
        "\n",
        "    history = vgg_model.fit(\n",
        "        X_train_fold,\n",
        "        y_train_fold_one_hot,\n",
        "        epochs=10,\n",
        "        validation_data=(X_val_fold, y_val_fold_one_hot),\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        class_weight=class_weights\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_acc = vgg_model.evaluate(X_val_fold, y_val_fold_one_hot, verbose=0)\n",
        "    print(f\"Validation Accuracy for Fold {fold}: {val_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y_test_one_hot=to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Function to calculate and print evaluation metrics\n",
        "def evaluate_model_multi_class(model, X, y_true):\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # Convert one-hot encoding to class labels\n",
        "    y_true_labels = np.argmax(y_true, axis=1)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true_labels, y_pred_labels))\n",
        "\n",
        "# Assuming you have trained the model 'inception_model' and loaded the test set 'X_val_fold', 'y_val_fold_one_hot'\n",
        "evaluate_model_multi_class(vgg_model, X_test, y_test_one_hot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwvAC3VwfosE",
        "outputId": "42f617e7-26b5-481a-c667-9272b6bf9263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 20s 529ms/step\n",
            "Accuracy: 100.00%\n",
            "Confusion Matrix:\n",
            "[[ 4  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 20]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        33\n",
            "   macro avg       1.00      1.00      1.00        33\n",
            "weighted avg       1.00      1.00      1.00        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "................................................................................................................................................................\n"
      ],
      "metadata": {
        "id": "_CK-7ejEtIq8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwOeAtCM4mcJ"
      },
      "source": [
        "IGNORE `\\/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMw-YqGuYrJ5",
        "outputId": "26adf04e-e13a-4a0f-9ed9-5388527e9be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Test Accuracy: 27.27%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the overall performance on the test set\n",
        "test_loss, test_acc = vgg_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nOverall Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxVjnpujUuAD"
      },
      "outputs": [],
      "source": [
        "# Number of folds for k-fold cross-validation\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train), 1):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    print(f\"Fold {fold} - Training Set: {len(X_train_fold)} samples, Validation Set: {len(X_val_fold)} samples\")\n",
        "\n",
        "    # Rest of your code (build model, train, evaluate) goes here\n",
        "\n",
        "    # Example: Print the first few labels in the training and validation sets\n",
        "    print(f\"First few labels in training set: {y_train_fold[:5]}\")\n",
        "    print(f\"First few labels in validation set: {y_val_fold[:5]}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJnb5lopr-aD"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Data augmentation\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=0,  # We will manually apply rotation\n",
        "#     vertical_flip=True,\n",
        "#     # No preprocessing_function specified for denoising or other operations\n",
        "# )\n",
        "\n",
        "# # Split the data into 90% training and 10% testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# # Apply augmentation to training data\n",
        "# X_train_augmented = []\n",
        "# y_train_augmented = []\n",
        "\n",
        "# # for i in range(len(X_train)):\n",
        "# #     # Apply rotation only to 90, 180, 270, and 0 degrees\n",
        "# #     for angle in [0, 90, 180, 270]:\n",
        "# #         rotated_image = datagen.apply_transform(X_train[i], {'theta': angle})\n",
        "# #         X_train_augmented.append(rotated_image)\n",
        "# #         y_train_augmented.append(y_train[i])\n",
        "# # Apply augmentation to training data\n",
        "# train_iterator = datagen.flow(X_train, y_train, batch_size=len(X_train), shuffle=False)\n",
        "# X_train_augmented, y_train_augmented = train_iterator.next()\n",
        "\n",
        "# X_train_augmented = np.array(X_train_augmented)\n",
        "# y_train_augmented = np.array(y_train_augmented)\n",
        "\n",
        "# # Print the sizes of the training and testing sets\n",
        "# print(f\"Original Training Set: {len(X_train)} samples\")\n",
        "# print(f\"Augmented Training Set: {len(X_train_augmented)} samples\")\n",
        "# print(f\"Original Testing Set: {len(X_test)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI7VBMHSoXzt"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import morphology  # Import the morphology module from scipy\n",
        "\n",
        "# Image preprocessing including noise removal, histogram equalization, and morphological analysis\n",
        "def preprocess_image(img):\n",
        "    # Apply denoising\n",
        "    denoised_img = cv2.medianBlur(img, 5)\n",
        "    # Apply morphological operations\n",
        "    eroded_img = morphology.binary_erosion(denoised_img).astype(np.uint8) * 255\n",
        "    dilated_img = morphology.binary_dilation(eroded_img).astype(np.uint8) * 255\n",
        "    # Normalize to [0, 1]\n",
        "    normalized_img = dilated_img / 255.0\n",
        "    return normalized_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aIErLDIq7f-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=360,  # Rotate at any angle within the specified range\n",
        "    vertical_flip=True,\n",
        "    #preprocessing_function=preprocess_image  # Denoising\n",
        ")\n",
        "\n",
        "# Split the data into 90% training and 10% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Apply augmentation to training data\n",
        "train_iterator = datagen.flow(X_train, y_train, batch_size=len(X_train), shuffle=False)\n",
        "X_train_augmented, y_train_augmented = train_iterator.next()\n",
        "\n",
        "# Apply morphological operations to training data\n",
        "X_train_augmented_morph = np.array([cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8)) for img in X_train_augmented])\n",
        "\n",
        "# Apply the same augmentation and morphological operations to test data\n",
        "X_test_augmented = datagen.standardize(X_test)\n",
        "X_test_augmented_morph = np.array([cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8)) for img in X_test_augmented])\n",
        "\n",
        "# Print the sizes of the training and testing sets\n",
        "print(f\"Original Training Set: {len(X_train)} samples\")\n",
        "print(f\"Augmented Training Set: {len(X_train_augmented_morph)} samples\")\n",
        "print(f\"Original Testing Set: {len(X_test)} samples\")\n",
        "print(f\"Augmented Testing Set: {len(X_test_augmented_morph)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCbBIMwtO03u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "# Assuming X and y are the images and labels obtained from the previous code\n",
        "# X, y = label_images(directory_path)\n",
        "\n",
        "# Number of splits for k-fold cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Outer loop for k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n",
        "    X_train_kfold, X_test_kfold = X[train_index], X[test_index]\n",
        "    y_train_kfold, y_test_kfold = y[train_index], y[test_index]\n",
        "\n",
        "    # Inner loop for splitting the training set into train and validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_kfold, y_train_kfold, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Now you can train your model using X_train and y_train, and validate using X_val and y_val\n",
        "    # ...\n",
        "\n",
        "    # At the end of each fold, you can evaluate on the test set (X_test_kfold, y_test_kfold)\n",
        "    # ...\n",
        "\n",
        "    print(f\"\\nFold {fold} - Train Set: {len(X_train)}, Validation Set: {len(X_val)}, Test Set: {len(X_test_kfold)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF2S6dfc9-tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a872d5e0-d574-4abc-9e2e-d0cb6ae06fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "# Define the base model (VGG16 without top layers)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# # Custom model for breast cancer detection\n",
        "# def build_model(learn_rate=1e-4):\n",
        "#     model = models.Sequential()\n",
        "#     model.add(base_model)\n",
        "#     model.add(layers.Flatten())\n",
        "#     model.add(layers.Dense(512, activation='relu'))\n",
        "#     model.add(BatchNormalization())  # Add Batch Normalization\n",
        "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#     optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=optimizer,\n",
        "#         loss='binary_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "#     return model\n",
        "def build_fine_tuned_vgg_model(learn_rate=1e-4, momentum=0.9):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "    # Freeze all layers except the last three\n",
        "    for layer in base_model.layers[:-3]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))  # Add dropout for regularization\n",
        "    model.add(layers.Dense(3, activation='softmax'))  # Change activation to 'softmax'\n",
        "\n",
        "    # model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = SGD(learning_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "fine_tuned_vgg_model = build_fine_tuned_vgg_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuyj8xGtPP6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "14db3ed8-18e2-485c-e8af-895fc79a08ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-18607a902692>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert labels to one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_train_fold_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_val_fold_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train_fold' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_fold_one_hot = to_categorical(y_train_fold, num_classes=3)\n",
        "y_val_fold_one_hot = to_categorical(y_val_fold, num_classes=3)\n",
        "\n",
        "# Assuming X and y are the images and labels obtained from the previous code\n",
        "# X, y = label_images(directory_path)\n",
        "\n",
        "# Number of folds for k-fold cross-validation\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train), 1):\n",
        "\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "    print(f\"\\nFold {fold} - Training Set: {len(X_train_fold)} samples, Validation Set: {len(X_val_fold)} samples\")\n",
        "\n",
        "    # Your model training and evaluation code goes here for each fold\n",
        "    # Train the model\n",
        "    class_weights = {0: 4.0, 1: 4.0, 2: 1.0}  # Adjust the weights based on class imbalance\n",
        "\n",
        "    # Train the model\n",
        "    history = fine_tuned_vgg_model.fit(\n",
        "        X_train_fold,\n",
        "        y_train_fold_one_hot,  # Use one-hot encoded labels\n",
        "        epochs=20,\n",
        "        validation_data=(X_val_fold, y_val_fold_one_hot),  # Use one-hot encoded labels\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        class_weight=class_weights\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_acc = fine_tuned_vgg_model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    print(f\"Validation Accuracy for Fold {fold + 1}: {val_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSyCOw6JzKtb",
        "outputId": "bc456921-94f8-4fdf-fba0-7c92ad8a8600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 43s 21s/step\n",
            "Accuracy: 98.44%\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0 42]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.98      1.00      0.99        42\n",
            "\n",
            "    accuracy                           0.98        64\n",
            "   macro avg       0.99      0.97      0.98        64\n",
            "weighted avg       0.98      0.98      0.98        64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Function to calculate and print evaluation metrics\n",
        "def evaluate_model_multi_class(model, X, y_true):\n",
        "    # Predictions\n",
        "    y_pred = vgg_model.predict(X)\n",
        "\n",
        "    # Convert one-hot encoding to class labels\n",
        "    y_true_labels = np.argmax(y_true, axis=1)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true_labels, y_pred_labels))\n",
        "\n",
        "# Assuming you have trained the model 'inception_model' and loaded the test set 'X_val_fold', 'y_val_fold_one_hot'\n",
        "evaluate_model_multi_class(vgg_model, X_val_fold, y_val_fold_one_hot)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pUn3ED4RnvEs1kF1J0ixAfKGPBkZDiMz",
      "authorship_tag": "ABX9TyOA8uMmKAV9NlCIaUo0Br06",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}